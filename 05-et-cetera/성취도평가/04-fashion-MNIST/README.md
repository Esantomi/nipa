# Fashion-MNIST 데이터 분류하기
Fashion-MNIST 데이터란 의류, 가방, 신발 등의 **패션 이미지들의 데이터셋**으로 60,000개의 학습용 데이터 셋과 10,000개의 테스트 데이터 셋으로 이루어져 있습니다.

각 이미지들은 **28x28 크기의 흑백 이미지**로, **총 10개의 클래스**로 분류되어 있습니다.

이번 실습에서 사용하는 데이터는 모델 학습을 위해 28x28 크기의 다차원 데이터를 1차원 배열로 전처리한 데이터로, 60,000개의 학습 데이터 중 **4,000개**의 학습 데이터와 10,000개의 테스트 데이터 중 **1,000개**의 데이터를 랜덤으로 추출하였습니다.

이번 실습에서는 이러한 Fashion-MNIST 데이터를 각 이미지의 레이블에 맞게 분류하는 다층 퍼셉트론 모델을 생성해보고, Test 데이터에 대한 정확도, 즉 모델의 성능을 **85% 이상**으로 높여보도록 하겠습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/61646760/146217417-39861c93-1966-46fa-8909-98b6fc24a839.png">
</p>

### 실습

Fashion-MNIST 데이터 분류를 위한 다층 퍼셉트론 모델을 생성하고, 학습 방법을 설정해 학습시킨 모델을 반환하는 Model 함수를 구현하세요.

1. 다층 퍼셉트론 분류 모델의 구조 예시입니다.

    - **첫 번째 레이어 (Input layer)**  
      이번 실습에서 사용하는 데이터는 이미 전처리 되어 있기 때문에 `input_dim` 인자를 통해 데이터의 크기를 맞춰주지 않아도 됩니다.
      - `tf.keras.layers.Dense(64, activation='relu')`

    - **마지막 레이어 (Output layer)**  
      10개 클래스에 대한 확률을 출력합니다.
      - `tf.keras.layers.Dense(10, activation='softmax')`

2. 모델을 학습시킬 손실 함수(loss function)와 최적화(optimize) 방법, 평가 방법(metrics)을 다음과 같이 설정합니다.

    - **손실 함수**(`loss`) : `'sparse_categorical_crossentropy'`
    - **최적화 방법**(`optimizer`) : `'adam'`
    - **평가 방법**(`metrics`) : `['accuracy']`

3. 모델을 학습시킵니다. 우리의 목표를 위해 epochs도 자유롭게 설정해 봅니다.

- 실행 버튼을 눌러 테스트 데이터에 대한 모델의 성능 즉, 테스트 정확도를 확인하고 **85% 이상**으로 높여 제출해 보세요.

## 결과
```
Train on 4000 samples
Epoch 1/6

  32/4000 [..............................] - ETA: 58s - loss: 2.6076 - accuracy: 0.0000e+00
1216/4000 [========>.....................] - ETA: 1s - loss: 1.5000 - accuracy: 0.5107     
2368/4000 [================>.............] - ETA: 0s - loss: 1.1957 - accuracy: 0.6064
3520/4000 [=========================>....] - ETA: 0s - loss: 1.0473 - accuracy: 0.6514
4000/4000 [==============================] - 1s 161us/sample - loss: 1.0144 - accuracy: 0.6635
Epoch 2/6

  32/4000 [..............................] - ETA: 0s - loss: 1.1077 - accuracy: 0.6250
1248/4000 [========>.....................] - ETA: 0s - loss: 0.6103 - accuracy: 0.7917
2432/4000 [=================>............] - ETA: 0s - loss: 0.6092 - accuracy: 0.7899
3616/4000 [==========================>...] - ETA: 0s - loss: 0.6169 - accuracy: 0.7920
4000/4000 [==============================] - 0s 43us/sample - loss: 0.6073 - accuracy: 0.7955
Epoch 3/6

  32/4000 [..............................] - ETA: 0s - loss: 0.3994 - accuracy: 0.8750
1216/4000 [========>.....................] - ETA: 0s - loss: 0.5551 - accuracy: 0.8133
2400/4000 [=================>............] - ETA: 0s - loss: 0.5518 - accuracy: 0.8133
3584/4000 [=========================>....] - ETA: 0s - loss: 0.5376 - accuracy: 0.8128
4000/4000 [==============================] - 0s 43us/sample - loss: 0.5294 - accuracy: 0.8188
Epoch 4/6

  32/4000 [..............................] - ETA: 0s - loss: 0.4989 - accuracy: 0.7188
1024/4000 [======>.......................] - ETA: 0s - loss: 0.4885 - accuracy: 0.8301
2016/4000 [==============>...............] - ETA: 0s - loss: 0.4866 - accuracy: 0.8368
3200/4000 [=======================>......] - ETA: 0s - loss: 0.4790 - accuracy: 0.8431
4000/4000 [==============================] - 0s 47us/sample - loss: 0.4725 - accuracy: 0.8435
Epoch 5/6

  32/4000 [..............................] - ETA: 0s - loss: 0.4274 - accuracy: 0.8125
1216/4000 [========>.....................] - ETA: 0s - loss: 0.4163 - accuracy: 0.8569
2400/4000 [=================>............] - ETA: 0s - loss: 0.4245 - accuracy: 0.8625
3584/4000 [=========================>....] - ETA: 0s - loss: 0.4410 - accuracy: 0.8527
4000/4000 [==============================] - 0s 43us/sample - loss: 0.4418 - accuracy: 0.8512
Epoch 6/6

  32/4000 [..............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.9062
1216/4000 [========>.....................] - ETA: 0s - loss: 0.4475 - accuracy: 0.8520
2400/4000 [=================>............] - ETA: 0s - loss: 0.4310 - accuracy: 0.8579
3584/4000 [=========================>....] - ETA: 0s - loss: 0.4382 - accuracy: 0.8597
4000/4000 [==============================] - 0s 43us/sample - loss: 0.4350 - accuracy: 0.8602
```
```
TEST 정확도 : 0.872
```
![1](https://user-images.githubusercontent.com/61646760/146217767-8140a67e-e62c-4b8e-9a81-43f69b1ba4f4.png)
```
Label:  5.0
Prediction:  5
```
![2](https://user-images.githubusercontent.com/61646760/146217788-66a23832-de63-4b06-b779-36f82f31c792.png)
```
Label:  4.0
Prediction:  2
```
![3](https://user-images.githubusercontent.com/61646760/146217821-ebf4a209-7158-489f-9d59-e7eb4fb8aa0c.png)
```
Label:  0.0
Prediction:  0
```
